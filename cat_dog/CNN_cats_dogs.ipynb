{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7ZiWkmiXKOT"
   },
   "source": [
    "# 복잡한 object 구별하기 (강이지 vs 고양이) : from Deep learning with Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wT_mTcixXKOZ"
   },
   "source": [
    "## 아래 코드는 \"케라스 창시자에게 배우는 딥러닝\"의  역자 Github (https://github.com/rickiepark/deep-learning-with-python-notebooks) 에서 받은 소스파일을 교육목적으로 재구성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ApB8KJYFXKOZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # The kernel appears to have died. It will restart automatically 문제 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jbMLGes3XKOa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "\n",
    "import os, shutil # 파일 연산을 위한 라이브러리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHAUqoe-XKOa"
   },
   "source": [
    "## 파이썬 기능을 사용하여, 파일 분류 \n",
    "이 주피터 노트북이 있는 폴더에 데이터 zip 을 압축 해제 하기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wxV4GztUXKOa"
   },
   "outputs": [],
   "source": [
    "# 원본 데이터셋을 압축 해제한 디렉터리 경로 \n",
    "original_dataset_dir = './datasets/cats_and_dogs/train'\n",
    "\n",
    "# 소규모 데이터셋을 저장할 디렉터리\n",
    "base_dir = './datasets/cats_and_dogs_small'\n",
    "\n",
    "if os.path.exists(base_dir):  # 반복적인 실행을 위해 디렉토리를 삭제합니다.\n",
    "    shutil.rmtree(base_dir)   \n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# 훈련용 고양이 사진 디렉터리\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "# 훈련용 강아지 사진 디렉터리\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "# 검증용 고양이 사진 디렉터리\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "# 검증용 강아지 사진 디렉터리\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# 테스트용 고양이 사진 디렉터리\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "\n",
    "# 테스트용 강아지 사진 디렉터리\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "# 처음 1,000개의 고양이 이미지를 train_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 500개 고양이 이미지를 validation_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 고양이 이미지를 test_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 강아지 이미지를 validation_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 강아지 이미지를 test_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ddAUIZW9XKOb",
    "outputId": "002ad917-c25a-49a3-b476-953199103d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 고양이 이미지 전체 개수: 1000\n",
      "훈련용 강아지 이미지 전체 개수: 1000\n",
      "검증용 고양이 이미지 전체 개수: 500\n",
      "검증용 강아지 이미지 전체 개수: 500\n",
      "테스트용 고양이 이미지 전체 개수: 500\n",
      "테스트용 강아지 이미지 전체 개수: 500\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 고양이 이미지 전체 개수:', len(os.listdir(train_cats_dir)))\n",
    "print('훈련용 강아지 이미지 전체 개수:', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "print('검증용 고양이 이미지 전체 개수:', len(os.listdir(validation_cats_dir)))\n",
    "print('검증용 강아지 이미지 전체 개수:', len(os.listdir(validation_dogs_dir)))\n",
    "\n",
    "print('테스트용 고양이 이미지 전체 개수:', len(os.listdir(test_cats_dir)))\n",
    "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FV1f3YvCXKOb"
   },
   "source": [
    "## 데이터 전처리 \n",
    "\n",
    "데이터는 네트워크에 주입되기 전에 부동 소수 타입의 텐서로 적절하게 전처리되어 있어야 합니다. 지금은 데이터가 JPEG 파일로 되어 있으므로 네트워크에 주입하려면 대략 다음 과정을 따릅니다.\n",
    "\n",
    "1.\t사진 파일을 읽습니다.\n",
    "2.\tJPEG 콘텐츠를 RGB 픽셀 값으로 디코딩합니다.\n",
    "3.\t그다음 부동 소수 타입의 텐서로 변환합니다.\n",
    "4.\t픽셀 값(0에서 255 사이)의 스케일을 [0, 1] 사이로 조정합니다(신경망은 작은 입력 값을 선호합니다).\n",
    "\n",
    "좀 복잡하게 보일 수 있지만 다행히 케라스는 이런 단계를 자동으로 처리하는 유틸리티를 가지고 있습니다. 케라스는 `keras.preprocessing.image`에 이미지 처리를 위한 헬퍼 도구들을 가지고 있습니다. 특히 `ImageDataGenerator` 클래스는 디스크에 있는 이미지 파일을 전처리된 배치 텐서로 자동으로 바꾸어주는 파이썬 제너레이터를 만들어 줍니다. 이 클래스를 사용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2CIv3pHZXKOb",
    "outputId": "e9b04001-221d-4d16-8ac7-055c71578735"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:51:16.049673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.068704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.069236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.070571: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-13 20:51:16.071555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.072056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.072530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.613177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.613537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.613858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 20:51:16.614293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6293 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    # 모든 이미지를 1/255로 스케일을 조정합니다\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            # 타깃 디렉터리\n",
    "            train_dir,\n",
    "            # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
    "            target_size=(150, 150),\n",
    "            batch_size=20,\n",
    "            # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다 (강아지 vs 고양이)\n",
    "            class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_dir,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=20,\n",
    "            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ATevazWaXKOc",
    "outputId": "b637d745-eb7e-4c62-da10-593797ebdec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 데이터 크기: (20, 150, 150, 3)\n",
      "배치 레이블 크기: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('배치 데이터 크기:', data_batch.shape)\n",
    "    print('배치 레이블 크기:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uGigzAAkXKOc",
    "outputId": "2d4ebaa8-f0bf-42f9-88fb-1ffc4d9ac852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_1ZJ4gRJXKOc"
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "h_-UGusUXKOd",
    "outputId": "37cbe081-6f44-4de6-eb5c-741f52fab897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:51:18.073826: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 54ms/step - loss: 0.6997 - accuracy: 0.4940 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 0.6848 - accuracy: 0.5180 - val_loss: 0.6850 - val_accuracy: 0.5930\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.6598 - accuracy: 0.5945 - val_loss: 0.6584 - val_accuracy: 0.5270\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.6516 - accuracy: 0.6020 - val_loss: 0.6448 - val_accuracy: 0.6340\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.6136 - accuracy: 0.6630 - val_loss: 0.5891 - val_accuracy: 0.6830\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.5764 - accuracy: 0.7020 - val_loss: 0.5769 - val_accuracy: 0.6960\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.5367 - accuracy: 0.7340 - val_loss: 0.5782 - val_accuracy: 0.6890\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.5269 - accuracy: 0.7435 - val_loss: 0.5247 - val_accuracy: 0.7340\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 0.4651 - accuracy: 0.7720 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.4406 - accuracy: 0.7855 - val_loss: 0.5507 - val_accuracy: 0.7340\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.3825 - accuracy: 0.8215 - val_loss: 0.6283 - val_accuracy: 0.7280\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.3145 - accuracy: 0.8665 - val_loss: 0.5530 - val_accuracy: 0.7590\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.2773 - accuracy: 0.8780 - val_loss: 0.6093 - val_accuracy: 0.7400\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 0.2035 - accuracy: 0.9170 - val_loss: 0.6644 - val_accuracy: 0.7480\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.1484 - accuracy: 0.9365 - val_loss: 0.6994 - val_accuracy: 0.7740\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.1070 - accuracy: 0.9625 - val_loss: 0.9664 - val_accuracy: 0.7480\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0799 - accuracy: 0.9720 - val_loss: 1.1298 - val_accuracy: 0.7490\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 0.0599 - accuracy: 0.9775 - val_loss: 1.0879 - val_accuracy: 0.7590\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0196 - accuracy: 0.9955 - val_loss: 1.4525 - val_accuracy: 0.7600\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 1.4983 - val_accuracy: 0.7720\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.7700\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 4.7640e-04 - accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.7760\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 3.1696e-04 - accuracy: 1.0000 - val_loss: 1.7309 - val_accuracy: 0.7730\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 2.3391e-04 - accuracy: 1.0000 - val_loss: 1.7794 - val_accuracy: 0.7770\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 1.8415e-04 - accuracy: 1.0000 - val_loss: 1.8190 - val_accuracy: 0.7780\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 1.4580e-04 - accuracy: 1.0000 - val_loss: 1.8546 - val_accuracy: 0.7760\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 1.1924e-04 - accuracy: 1.0000 - val_loss: 1.8833 - val_accuracy: 0.7710\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 9.8909e-05 - accuracy: 1.0000 - val_loss: 1.9120 - val_accuracy: 0.7720\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 8.3444e-05 - accuracy: 1.0000 - val_loss: 1.9400 - val_accuracy: 0.7730\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 7.1249e-05 - accuracy: 1.0000 - val_loss: 1.9603 - val_accuracy: 0.7720\n"
     ]
    }
   ],
   "source": [
    "# history= model.fit(train_images,train_labels,epochs=20, batch_size=100, verbose=2,validation_data=(test_images, test_labels))\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,  \n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vXpq7QQcXKOd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_jSm1rCsXKOd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l8h84oXXKOd"
   },
   "source": [
    "## Question: \n",
    "\n",
    "\n",
    "<img src=\"overfitting.png\" width=\"70%\">\n",
    "\n",
    "현재 테스트에서 overfitting이 일어나고 있습니다.\n",
    "수업 시간에 배웠던 다양한 방법을 통해 overfitting을 최소화 시키고, 결과를 위와 같이 그래프로 표시하세요. \n",
    "결과값이 나타낸 대로 저장을 하여 제출하시기 바랍니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yyxKEsi-bCYA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "with tf.device('/gpu:0'):\n",
    "    # 모든 이미지를 1/255로 스케일을 조정합니다\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                       #samplewise_std_normalization=True,\n",
    "                                       shear_range = 0.2,#data augmentation을 통해 data 수를 늘린다(data의 질은 좋지 못함)=>overfitting 방지\n",
    "                                       zoom_range = 0.2,\n",
    "                                       rotation_range = 30,\n",
    "                                       #brightness_range=(0.8,1.2),\n",
    "                                       horizontal_flip = True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            # 타깃 디렉터리\n",
    "            train_dir,\n",
    "            # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
    "            target_size=(150, 150),\n",
    "            batch_size=20,\n",
    "            # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다 (강아지 vs 고양이)\n",
    "            class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_dir,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=20,\n",
    "            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uqZODza-XKOd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 148, 148, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 148, 148, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 72, 72, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 72, 72, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 34, 34, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 34, 34, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 17, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 15, 15, 64)        73792     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 15, 15, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,776,897\n",
      "Trainable params: 1,775,297\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization, Dropout, Activation\n",
    "\n",
    "#https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout\n",
    "with tf.device('/gpu:0'):\n",
    "    model = models.Sequential()#모델을 간단화(학습해야 할 파라미터 수를 줄임)=>복잡함으로 인한 overfitting 방지\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3),input_shape=(150, 150, 3),kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.001)))#regulization(0에 가까운 가중치는 0으로 & 가중치 값이 너무 크지 않도록)을 통한 overfitting 방지\n",
    "    model.add(BatchNormalization())#batch normalization을 통한 overfitting 방지(regularize효과)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3),kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3),kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3),kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(512,kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))#drop out을 통한 overfitting 방지(robust한 모델, 특정 data에 과하게 학습되지 않도록)\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    #https://link.springer.com/article/10.1007/s11042-019-08453-9의 자료를 참고하여 CNN에서는 dropout을 사용하지 않았다.\n",
    "    #일부 자료에서는 dropout과 batch normalization이 같은 효과를 가진다고 주장하는데 그 이유를 잘 모르겠어서 둘다 사용했습니다.\n",
    "    #l1,l2 regularize을 쓰지 않으면 val loss가 증가하는(국소적으로 증가하는 것이 아닌) 현상이 발생해서 사용하였습니다.(데이터가 적어 더욱 강한 규제 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "T1S_cyd95RYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 5.2144 - accuracy: 0.5740\n",
      "Epoch 00001: val_loss improved from inf to 4.69788, saving model to model.h5\n",
      "100/100 [==============================] - 11s 98ms/step - loss: 5.2144 - accuracy: 0.5740 - val_loss: 4.6979 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7669 - accuracy: 0.6515\n",
      "Epoch 00002: val_loss improved from 4.69788 to 3.42143, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 3.7669 - accuracy: 0.6515 - val_loss: 3.4214 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8639 - accuracy: 0.6770\n",
      "Epoch 00003: val_loss improved from 3.42143 to 2.69673, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 2.8639 - accuracy: 0.6770 - val_loss: 2.6967 - val_accuracy: 0.5040\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2508 - accuracy: 0.6820\n",
      "Epoch 00004: val_loss improved from 2.69673 to 2.10511, saving model to model.h5\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 2.2508 - accuracy: 0.6820 - val_loss: 2.1051 - val_accuracy: 0.5800\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8832 - accuracy: 0.6850\n",
      "Epoch 00005: val_loss improved from 2.10511 to 1.74052, saving model to model.h5\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 1.8832 - accuracy: 0.6850 - val_loss: 1.7405 - val_accuracy: 0.6410\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5805 - accuracy: 0.7065\n",
      "Epoch 00006: val_loss improved from 1.74052 to 1.67698, saving model to model.h5\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 1.5805 - accuracy: 0.7065 - val_loss: 1.6770 - val_accuracy: 0.5750\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4148 - accuracy: 0.7190\n",
      "Epoch 00007: val_loss improved from 1.67698 to 1.55653, saving model to model.h5\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 1.4148 - accuracy: 0.7190 - val_loss: 1.5565 - val_accuracy: 0.5820\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2844 - accuracy: 0.7310\n",
      "Epoch 00008: val_loss improved from 1.55653 to 1.21135, saving model to model.h5\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 1.2844 - accuracy: 0.7310 - val_loss: 1.2113 - val_accuracy: 0.7300\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2213 - accuracy: 0.7470\n",
      "Epoch 00009: val_loss improved from 1.21135 to 1.12954, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 1.2213 - accuracy: 0.7470 - val_loss: 1.1295 - val_accuracy: 0.7530\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1540 - accuracy: 0.7370\n",
      "Epoch 00010: val_loss did not improve from 1.12954\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 1.1540 - accuracy: 0.7370 - val_loss: 1.3532 - val_accuracy: 0.6120\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1023 - accuracy: 0.7235\n",
      "Epoch 00011: val_loss improved from 1.12954 to 1.09892, saving model to model.h5\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 1.1023 - accuracy: 0.7235 - val_loss: 1.0989 - val_accuracy: 0.7230\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1091 - accuracy: 0.7270\n",
      "Epoch 00012: val_loss did not improve from 1.09892\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 1.1091 - accuracy: 0.7270 - val_loss: 1.4140 - val_accuracy: 0.5480\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0312 - accuracy: 0.7410\n",
      "Epoch 00013: val_loss improved from 1.09892 to 1.05499, saving model to model.h5\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 1.0312 - accuracy: 0.7410 - val_loss: 1.0550 - val_accuracy: 0.7020\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0255 - accuracy: 0.7370\n",
      "Epoch 00014: val_loss did not improve from 1.05499\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 1.0255 - accuracy: 0.7370 - val_loss: 1.2181 - val_accuracy: 0.6600\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.7385\n",
      "Epoch 00015: val_loss improved from 1.05499 to 1.00284, saving model to model.h5\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 1.0114 - accuracy: 0.7385 - val_loss: 1.0028 - val_accuracy: 0.7320\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9977 - accuracy: 0.7475\n",
      "Epoch 00016: val_loss improved from 1.00284 to 0.94572, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9977 - accuracy: 0.7475 - val_loss: 0.9457 - val_accuracy: 0.7640\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9870 - accuracy: 0.7505\n",
      "Epoch 00017: val_loss did not improve from 0.94572\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9870 - accuracy: 0.7505 - val_loss: 1.0203 - val_accuracy: 0.7280\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9967 - accuracy: 0.7390\n",
      "Epoch 00018: val_loss did not improve from 0.94572\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.9967 - accuracy: 0.7390 - val_loss: 1.5120 - val_accuracy: 0.5340\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9580 - accuracy: 0.7455\n",
      "Epoch 00019: val_loss improved from 0.94572 to 0.92330, saving model to model.h5\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.9580 - accuracy: 0.7455 - val_loss: 0.9233 - val_accuracy: 0.7730\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.7485\n",
      "Epoch 00020: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.9646 - accuracy: 0.7485 - val_loss: 1.0183 - val_accuracy: 0.6890\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9620 - accuracy: 0.7465\n",
      "Epoch 00021: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.9620 - accuracy: 0.7465 - val_loss: 1.1082 - val_accuracy: 0.6830\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.7390\n",
      "Epoch 00022: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9643 - accuracy: 0.7390 - val_loss: 0.9883 - val_accuracy: 0.7150\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9659 - accuracy: 0.7470\n",
      "Epoch 00023: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.9659 - accuracy: 0.7470 - val_loss: 0.9791 - val_accuracy: 0.7560\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9595 - accuracy: 0.7335\n",
      "Epoch 00024: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9595 - accuracy: 0.7335 - val_loss: 0.9578 - val_accuracy: 0.6990\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 0.7490\n",
      "Epoch 00025: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.9380 - accuracy: 0.7490 - val_loss: 0.9485 - val_accuracy: 0.7470\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9450 - accuracy: 0.7610\n",
      "Epoch 00026: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.9450 - accuracy: 0.7610 - val_loss: 1.0222 - val_accuracy: 0.7080\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9203 - accuracy: 0.7685\n",
      "Epoch 00027: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9203 - accuracy: 0.7685 - val_loss: 1.0393 - val_accuracy: 0.6780\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9579 - accuracy: 0.7445\n",
      "Epoch 00028: val_loss did not improve from 0.92330\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.9579 - accuracy: 0.7445 - val_loss: 1.3131 - val_accuracy: 0.5850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9319 - accuracy: 0.7690\n",
      "Epoch 00029: val_loss improved from 0.92330 to 0.92123, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9319 - accuracy: 0.7690 - val_loss: 0.9212 - val_accuracy: 0.7820\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9378 - accuracy: 0.7565\n",
      "Epoch 00030: val_loss did not improve from 0.92123\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.9378 - accuracy: 0.7565 - val_loss: 1.0668 - val_accuracy: 0.7140\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.7510\n",
      "Epoch 00031: val_loss improved from 0.92123 to 0.88810, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9588 - accuracy: 0.7510 - val_loss: 0.8881 - val_accuracy: 0.7780\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9118 - accuracy: 0.7685\n",
      "Epoch 00032: val_loss did not improve from 0.88810\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.9118 - accuracy: 0.7685 - val_loss: 0.8923 - val_accuracy: 0.7680\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9376 - accuracy: 0.7655\n",
      "Epoch 00033: val_loss did not improve from 0.88810\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.9376 - accuracy: 0.7655 - val_loss: 1.1284 - val_accuracy: 0.6240\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9049 - accuracy: 0.7655\n",
      "Epoch 00034: val_loss did not improve from 0.88810\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.9049 - accuracy: 0.7655 - val_loss: 1.3250 - val_accuracy: 0.6460\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9067 - accuracy: 0.7660\n",
      "Epoch 00035: val_loss improved from 0.88810 to 0.86308, saving model to model.h5\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.9067 - accuracy: 0.7660 - val_loss: 0.8631 - val_accuracy: 0.7700\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8898 - accuracy: 0.7710\n",
      "Epoch 00036: val_loss did not improve from 0.86308\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.8898 - accuracy: 0.7710 - val_loss: 0.9413 - val_accuracy: 0.7350\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9063 - accuracy: 0.7680\n",
      "Epoch 00037: val_loss did not improve from 0.86308\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.9063 - accuracy: 0.7680 - val_loss: 0.9470 - val_accuracy: 0.7380\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8859 - accuracy: 0.7760\n",
      "Epoch 00038: val_loss did not improve from 0.86308\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8859 - accuracy: 0.7760 - val_loss: 0.9268 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8955 - accuracy: 0.7665\n",
      "Epoch 00039: val_loss improved from 0.86308 to 0.85226, saving model to model.h5\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.8955 - accuracy: 0.7665 - val_loss: 0.8523 - val_accuracy: 0.8050\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8895 - accuracy: 0.7730\n",
      "Epoch 00040: val_loss did not improve from 0.85226\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8895 - accuracy: 0.7730 - val_loss: 0.8852 - val_accuracy: 0.7760\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8911 - accuracy: 0.7800\n",
      "Epoch 00041: val_loss improved from 0.85226 to 0.84387, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8911 - accuracy: 0.7800 - val_loss: 0.8439 - val_accuracy: 0.7850\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.7695\n",
      "Epoch 00042: val_loss did not improve from 0.84387\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8701 - accuracy: 0.7695 - val_loss: 0.9448 - val_accuracy: 0.7330\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8820 - accuracy: 0.7785\n",
      "Epoch 00043: val_loss did not improve from 0.84387\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8820 - accuracy: 0.7785 - val_loss: 0.9711 - val_accuracy: 0.7330\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.7675\n",
      "Epoch 00044: val_loss improved from 0.84387 to 0.83102, saving model to model.h5\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.8645 - accuracy: 0.7675 - val_loss: 0.8310 - val_accuracy: 0.7760\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8728 - accuracy: 0.7805\n",
      "Epoch 00045: val_loss did not improve from 0.83102\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.8728 - accuracy: 0.7805 - val_loss: 0.8944 - val_accuracy: 0.7650\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8397 - accuracy: 0.7825\n",
      "Epoch 00046: val_loss did not improve from 0.83102\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8397 - accuracy: 0.7825 - val_loss: 0.9737 - val_accuracy: 0.6760\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8242 - accuracy: 0.7890\n",
      "Epoch 00047: val_loss improved from 0.83102 to 0.78109, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8242 - accuracy: 0.7890 - val_loss: 0.7811 - val_accuracy: 0.8090\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8420 - accuracy: 0.7700\n",
      "Epoch 00048: val_loss did not improve from 0.78109\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.8420 - accuracy: 0.7700 - val_loss: 0.9379 - val_accuracy: 0.7220\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8262 - accuracy: 0.7900\n",
      "Epoch 00049: val_loss did not improve from 0.78109\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8262 - accuracy: 0.7900 - val_loss: 0.8638 - val_accuracy: 0.7440\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8095 - accuracy: 0.7745\n",
      "Epoch 00050: val_loss did not improve from 0.78109\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.8095 - accuracy: 0.7745 - val_loss: 0.8253 - val_accuracy: 0.7940\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7695 - accuracy: 0.7990\n",
      "Epoch 00051: val_loss improved from 0.78109 to 0.76818, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.7695 - accuracy: 0.7990 - val_loss: 0.7682 - val_accuracy: 0.8110\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8059 - accuracy: 0.7900\n",
      "Epoch 00052: val_loss did not improve from 0.76818\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.8059 - accuracy: 0.7900 - val_loss: 0.8132 - val_accuracy: 0.7900\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8094 - accuracy: 0.7890\n",
      "Epoch 00053: val_loss did not improve from 0.76818\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.8094 - accuracy: 0.7890 - val_loss: 1.0573 - val_accuracy: 0.6600\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7720 - accuracy: 0.8015\n",
      "Epoch 00054: val_loss did not improve from 0.76818\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.7720 - accuracy: 0.8015 - val_loss: 0.8106 - val_accuracy: 0.7900\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7928 - accuracy: 0.7915\n",
      "Epoch 00055: val_loss did not improve from 0.76818\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.7928 - accuracy: 0.7915 - val_loss: 0.8299 - val_accuracy: 0.7600\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.8050\n",
      "Epoch 00056: val_loss improved from 0.76818 to 0.76105, saving model to model.h5\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 0.7668 - accuracy: 0.8050 - val_loss: 0.7610 - val_accuracy: 0.8070\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.7710 - accuracy: 0.8030\n",
      "Epoch 00057: val_loss did not improve from 0.76105\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.7710 - accuracy: 0.8030 - val_loss: 1.0586 - val_accuracy: 0.6690\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.8015\n",
      "Epoch 00058: val_loss did not improve from 0.76105\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.7542 - accuracy: 0.8015 - val_loss: 0.7724 - val_accuracy: 0.7910\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7552 - accuracy: 0.8015\n",
      "Epoch 00059: val_loss did not improve from 0.76105\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.7552 - accuracy: 0.8015 - val_loss: 0.8615 - val_accuracy: 0.7330\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7507 - accuracy: 0.8035\n",
      "Epoch 00060: val_loss improved from 0.76105 to 0.73520, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.7507 - accuracy: 0.8035 - val_loss: 0.7352 - val_accuracy: 0.8160\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7678 - accuracy: 0.7895\n",
      "Epoch 00061: val_loss did not improve from 0.73520\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.7678 - accuracy: 0.7895 - val_loss: 0.7495 - val_accuracy: 0.7990\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.7945\n",
      "Epoch 00062: val_loss did not improve from 0.73520\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.7647 - accuracy: 0.7945 - val_loss: 0.9294 - val_accuracy: 0.7100\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7363 - accuracy: 0.8085\n",
      "Epoch 00063: val_loss improved from 0.73520 to 0.71770, saving model to model.h5\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.7363 - accuracy: 0.8085 - val_loss: 0.7177 - val_accuracy: 0.8250\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.7955\n",
      "Epoch 00064: val_loss did not improve from 0.71770\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.7569 - accuracy: 0.7955 - val_loss: 0.7942 - val_accuracy: 0.7730\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7424 - accuracy: 0.8035\n",
      "Epoch 00065: val_loss did not improve from 0.71770\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.7424 - accuracy: 0.8035 - val_loss: 0.7728 - val_accuracy: 0.7650\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.8105\n",
      "Epoch 00066: val_loss did not improve from 0.71770\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.7176 - accuracy: 0.8105 - val_loss: 0.7663 - val_accuracy: 0.7870\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7058 - accuracy: 0.8105\n",
      "Epoch 00067: val_loss did not improve from 0.71770\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.7058 - accuracy: 0.8105 - val_loss: 0.7463 - val_accuracy: 0.8120\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7293 - accuracy: 0.8130\n",
      "Epoch 00068: val_loss did not improve from 0.71770\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.7293 - accuracy: 0.8130 - val_loss: 0.9264 - val_accuracy: 0.7180\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7242 - accuracy: 0.7940\n",
      "Epoch 00069: val_loss improved from 0.71770 to 0.69910, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.7242 - accuracy: 0.7940 - val_loss: 0.6991 - val_accuracy: 0.8140\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.8205\n",
      "Epoch 00070: val_loss improved from 0.69910 to 0.69272, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6946 - accuracy: 0.8205 - val_loss: 0.6927 - val_accuracy: 0.8120\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.8085\n",
      "Epoch 00071: val_loss improved from 0.69272 to 0.67945, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.7142 - accuracy: 0.8085 - val_loss: 0.6795 - val_accuracy: 0.8110\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6818 - accuracy: 0.8190\n",
      "Epoch 00072: val_loss did not improve from 0.67945\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.6818 - accuracy: 0.8190 - val_loss: 0.6887 - val_accuracy: 0.8020\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.8095\n",
      "Epoch 00073: val_loss improved from 0.67945 to 0.66541, saving model to model.h5\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6985 - accuracy: 0.8095 - val_loss: 0.6654 - val_accuracy: 0.8080\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.8090\n",
      "Epoch 00074: val_loss did not improve from 0.66541\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6968 - accuracy: 0.8090 - val_loss: 0.8279 - val_accuracy: 0.7520\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.8125\n",
      "Epoch 00075: val_loss did not improve from 0.66541\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.6852 - accuracy: 0.8125 - val_loss: 0.7270 - val_accuracy: 0.7910\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.8240\n",
      "Epoch 00076: val_loss did not improve from 0.66541\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.6807 - accuracy: 0.8240 - val_loss: 0.7000 - val_accuracy: 0.8140\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.8100\n",
      "Epoch 00077: val_loss did not improve from 0.66541\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6922 - accuracy: 0.8100 - val_loss: 0.7301 - val_accuracy: 0.7940\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.8165\n",
      "Epoch 00078: val_loss did not improve from 0.66541\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.6700 - accuracy: 0.8165 - val_loss: 0.6891 - val_accuracy: 0.7940\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.8300\n",
      "Epoch 00079: val_loss improved from 0.66541 to 0.64533, saving model to model.h5\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6547 - accuracy: 0.8300 - val_loss: 0.6453 - val_accuracy: 0.8360\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.8120\n",
      "Epoch 00080: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6710 - accuracy: 0.8120 - val_loss: 0.6666 - val_accuracy: 0.8190\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.8105\n",
      "Epoch 00081: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6834 - accuracy: 0.8105 - val_loss: 0.8610 - val_accuracy: 0.7020\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.8330\n",
      "Epoch 00082: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6497 - accuracy: 0.8330 - val_loss: 0.6785 - val_accuracy: 0.8140\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6473 - accuracy: 0.8320\n",
      "Epoch 00083: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6473 - accuracy: 0.8320 - val_loss: 0.7675 - val_accuracy: 0.7750\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6407 - accuracy: 0.8220\n",
      "Epoch 00084: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.6407 - accuracy: 0.8220 - val_loss: 0.7730 - val_accuracy: 0.7460\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.6468 - accuracy: 0.8220\n",
      "Epoch 00085: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.6468 - accuracy: 0.8220 - val_loss: 0.7702 - val_accuracy: 0.7730\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.8300\n",
      "Epoch 00086: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6296 - accuracy: 0.8300 - val_loss: 0.7035 - val_accuracy: 0.7870\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 0.8180\n",
      "Epoch 00087: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6704 - accuracy: 0.8180 - val_loss: 0.6747 - val_accuracy: 0.8170\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6327 - accuracy: 0.8415\n",
      "Epoch 00088: val_loss did not improve from 0.64533\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.6327 - accuracy: 0.8415 - val_loss: 0.8091 - val_accuracy: 0.7230\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.8100\n",
      "Epoch 00089: val_loss improved from 0.64533 to 0.61752, saving model to model.h5\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6539 - accuracy: 0.8100 - val_loss: 0.6175 - val_accuracy: 0.8440\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6415 - accuracy: 0.8320\n",
      "Epoch 00090: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6415 - accuracy: 0.8320 - val_loss: 0.7582 - val_accuracy: 0.7800\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6308 - accuracy: 0.8300\n",
      "Epoch 00091: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.6308 - accuracy: 0.8300 - val_loss: 0.6279 - val_accuracy: 0.8350\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.8365\n",
      "Epoch 00092: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.6139 - accuracy: 0.8365 - val_loss: 0.6742 - val_accuracy: 0.8120\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.8380\n",
      "Epoch 00093: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.6275 - accuracy: 0.8380 - val_loss: 0.7233 - val_accuracy: 0.8010\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.8460\n",
      "Epoch 00094: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6066 - accuracy: 0.8460 - val_loss: 0.8671 - val_accuracy: 0.7140\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.8295\n",
      "Epoch 00095: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.6419 - accuracy: 0.8295 - val_loss: 0.6347 - val_accuracy: 0.8250\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.8225\n",
      "Epoch 00096: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6289 - accuracy: 0.8225 - val_loss: 0.6443 - val_accuracy: 0.8280\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.8380\n",
      "Epoch 00097: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.6079 - accuracy: 0.8380 - val_loss: 0.6360 - val_accuracy: 0.8200\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.8285\n",
      "Epoch 00098: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.6328 - accuracy: 0.8285 - val_loss: 0.6304 - val_accuracy: 0.8240\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6089 - accuracy: 0.8350\n",
      "Epoch 00099: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.6089 - accuracy: 0.8350 - val_loss: 0.6473 - val_accuracy: 0.8170\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.8355\n",
      "Epoch 00100: val_loss did not improve from 0.61752\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.6172 - accuracy: 0.8355 - val_loss: 0.6265 - val_accuracy: 0.8350\n"
     ]
    }
   ],
   "source": [
    "# history= model.fit(train_images,train_labels,epochs=20, batch_size=100, verbose=2,validation_data=(test_images, test_labels))\n",
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(filepath='model.h5',save_best_only=True ,verbose=1) #best acc model 저장\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,  \n",
    "        epochs=100,#여러 규제들을 적용하여 학습 속도가 느려짐=>epoch을 늘려 더 오래 학습시킴, 실제로는 50 epoch이 넘어가면 점점 overfitting이 되지만 val_acc이 안정되어서 다음과 같이 했다. 순간적인 acc만 볼 것이면 50이어도 충분하다.\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[cp_callback],\n",
    "        validation_steps=50\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "huuctq_I5R8x"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.history.keys()\n",
    "model.save('CatsDogs.h5')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.ylim([0.0, 1.0]) \n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#https://stats.stackexchange.com/questions/255105/why-is-the-validation-accuracy-fluctuating\n",
    "#에 의하면 data가 충분하지 못해서 fluctuating이 발생하는 것 같다. 개인적인 의견으로 운이 좋게 validation dataset에 알맞게 train이 된 것으로 보인다.\n",
    "#조금 더 넓은 폭의 data에 대해서라면 epoch을 늘린 모델이 적합할 것으로 보인다(epoch이 늘어날 수록 fluctuating이 줄어듬)\n",
    "\n",
    "#dataset 이미지를 확인해보았는데 고양이가 여러마리 있거나 물체에 가려져있거나 사람과 같이 있거나, 글씨가 있는 등 여러 경우가 있다.(좋지 못한 dataset,고양이와 개만 있는 데이터가 아님)\n",
    "#이러한 dataset에 대해 cat dog로 구분하기에는 힘들어 보이고 실제로도 그렇다. RCNN처럼 selective search(혹은 전처리:원래 되어 있어야 하는)를 한 후 classify를 하면 더 좋은 성능의 모델을 얻을 수 있을 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best training loss:0.6066\n",
      "best validation loss:0.6175\n",
      "\n",
      "best training accuracy:0.8460\n",
      "best validation accuracy:0.8440\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"best training loss:{np.min(loss):.4f}\\nbest validation loss:{np.min(val_loss):.4f}\\n\")\n",
    "print(f\"best training accuracy:{np.max(acc):.4f}\\nbest validation accuracy:{np.max(val_acc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3lM3cjbyiKcl"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "best_model = load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OSqgpS2TQZXl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.6835 - accuracy: 0.7990\n",
      "test loss:0.684, test acc:0.799\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "results = best_model.evaluate(test_datagen)\n",
    "print(f\"test loss:{results[0]:.3f}, test acc:{results[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-SgFury48u6"
   },
   "source": [
    "# 평가\n",
    "\n",
    "<p>주어진 모델은 최대 val_acc가 0.7330, 설계한 모델은 최대 val_acc가 0.8720으로 성능 향상이 있었다.</p> \n",
    "\n",
    "> 여러번 실험해본 결과 데이터가 어떻게 split되느냐에 따라 전체적인 acc 평균이 크게 달라진다.(acc_2 = acc_1 +(-0.05~0.05))\n",
    "\n",
    "<br>\n",
    "<p>plot을 보면 주어진 모델은 val_loss가 epoch가 10일 때부터 증가함수 형태를 띄어 overfitting이 발생했음을 알 수 있다. 반면 설계한 모델은 val_loss에서 fluctuation이 발생하지만 주석에서 설명했듯이 강한 규제에 데이터 수가 적어 특정학습에서 우연히 좋게 평가되거나 나쁘게 평가되어 발생하는 문제로 보인다. 물론 epoch이 50이 넘어가면서 overfitting이 생기지만 주어진 모델보다 약하다.</p>\n",
    "<br>\n",
    "<p>주석에서 설명했듯 설계한 모델은 아래와 같은 방법을 통해 overfitting을 방지했다.</p>\n",
    "\n",
    "  * 1. 모델을 간략화하여 가중치 수를 줄였다.\n",
    "  * 2. l1,l2 regularization을 통해 가중치 크기를 줄였다.\n",
    "  * 3. batch normalization을 사용하였다.\n",
    "  * 4. dropout을 사용하였다.\n",
    "  * 5. data augmentation을 사용하였다.\n",
    "\n",
    "  > 자세한 내용 및 참고 자료는 주석부분 참고\n",
    "\n",
    "<p>val_loss가 가장 낮은 모델로 test한 결과 0.8480의 acc를 얻을 수 있었다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_cats_dogs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
